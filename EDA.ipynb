{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b982cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from Dataset import LOBDataset\n",
    "from utils import weighted_pearson_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb35cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ba32da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_file = BASE_DIR / \"datasets/train.parquet\"\n",
    "test_dataset_file = BASE_DIR / \"datasets/valid.parquet\"\n",
    "learning_rate = 1e-3\n",
    "nepochs = 10\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e24ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "##sequence dimension\n",
    "n_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11077d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = LOBDataset(train_dataset_file, n_steps=n_steps, labels=['t0', 't1'])\n",
    "dataset_test = LOBDataset(test_dataset_file,n_steps=n_steps, labels=['t0', 't1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61f786d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sequences: 10721\n",
      "Number of testing sequences: 1444\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training sequences: {dataset_train.__n_sequences__()}')\n",
    "print(f'Number of testing sequences: {dataset_test.__n_sequences__()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cde38be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps: 1000\n",
      "Number of testing steps: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training steps: {len(dataset_train)}')\n",
    "print(f'Number of testing steps: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e7655bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_parquet(train_dataset_file, engine='pyarrow')\n",
    "#df.set_index(['seq_ix', 'step_in_seq', 'need_prediction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "381b61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_normalized = (df.groupby(level=0).apply(lambda x: (x - x.mean()) / x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "497435cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_normalized.reset_index(level=0, drop=True, inplace=True)\n",
    "#features_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6b0065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33cde7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hidden_size = 128\n",
    "num_layers=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19e46a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our network class using nn.Module\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        # Define layers for the MLP block\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, input_size) ##reduce complexity divide by 2\n",
    "        self.norm2 = nn.LayerNorm(input_size)\n",
    "        self.fc2 = nn.Linear(input_size, output_size) ##reduce complexity divide by 2\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        self.act = nn.ELU() #elementwise relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the MLP block\n",
    "        x = self.act(self.norm1(x))\n",
    "        skip = self.fc3(x)  # Skip connection\n",
    "        x = self.act(self.norm2(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x + skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f4b74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_features,  output_size, num_blocks=1, num_layers=1, hidden_size=128):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        # Define layers for input MLP, LSTM, residual blocks, and output linear layer\n",
    "        self.input_mlp = nn.Sequential(nn.Linear(n_features, hidden_size*4), #expand size \n",
    "                                       nn.ELU(),\n",
    "                                       nn.Linear(4*hidden_size, hidden_size))\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        blocks = [ResBlockMLP(hidden_size, hidden_size) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.act = nn.ELU()\n",
    "    \n",
    "    def forward(self, input_seq, hidden_in, mem_in):\n",
    "        B, T, _ = input_seq.shape\n",
    "        # Pass input sequence through the input MLP\n",
    "        input_vec = self.input_mlp(input_seq)\n",
    "        \n",
    "        # Pass the input MLP output through the LSTM block\n",
    "        output, (hidden_out, mem_out) = self.lstm(input_vec, (hidden_in, mem_in))\n",
    "        \n",
    "        # Pass the LSTM output through residual blocks\n",
    "        x = self.act(self.res_blocks(output))\n",
    "\n",
    "        x = x.reshape(B*T, -1)\n",
    "        x = self.fc_out(x)\n",
    "        x = x.reshape(B,T,-1)\n",
    "        \n",
    "        # Pass the output of the residual blocks through the final linear layer\n",
    "        return x, hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a40a694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "lob_lstm = LSTM(n_features=32, output_size=2, num_layers=num_layers, hidden_size=hidden_size).to(device)\n",
    "\n",
    "# Initialize the optimizer with Adam and specified learning rate\n",
    "optimizer = optim.Adam(lob_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function as Mean Squared Error\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Initialize a list to log training losses\n",
    "training_loss_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "702d2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-This Model Has 264962 (Approximately 0 Million) Parameters!\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in lob_lstm.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbf877fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c5f35350ee459ca76d6a644743ee55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca48c5db626a4fa59f4f4ccabbc73522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d697a66a4f2541d8ab6e1d19c0d607c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ef1825501642ceb72f29cc17919559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3286ab1189704cd997b059641b05972b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86327b685614fbb9e1f2f42297409cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddb3b9e0c1a4026b075601d25e7c4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5edcb4cf2c4a429bb18aadd7c06fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de14febfc1d4bdaa8682c8d7ac3d9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356a3aa3fad448bba56c70cf4cab45fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0580dfd559b249e2bc73b190c959c359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run training loop for each epoch\n",
    "for epoch in trange(nepochs, desc=\"Epochs\", leave=False):\n",
    "    # Set the model to training mode\n",
    "    lob_lstm.train()\n",
    "\n",
    "    for seq_id, data_seq in tqdm(data_loader_train, desc='Training', leave=False):\n",
    "        \n",
    "        # last two columns are labels\n",
    "        seq_block = data_seq[:,:,:-2].to(device)\n",
    "        target_seq_block = data_seq[:,:,-2:].to(device)\n",
    "\n",
    "        hidden = torch.zeros(num_layers, data_seq.shape[0], hidden_size, device=device)\n",
    "        memory = torch.zeros(num_layers, data_seq.shape[0], hidden_size, device=device)\n",
    "        \n",
    "        data_pred, hidden, memory = lob_lstm(seq_block, hidden, memory)\n",
    "\n",
    "        loss = loss_fn(data_pred, target_seq_block)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss_logger.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10ac04ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_loss_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "374265af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(training_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3608b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test dataset to tensor\n",
    "data_tensor = dataset_test.dataset\n",
    "log_predictions = []\n",
    "lob_lstm.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    seq_block = data_tensor[:, :, :-2].to(device) #(n_seq, seq_len, n_features)\n",
    "    batch_size = seq_block.shape[0]\n",
    "\n",
    "    hidden = torch.zeros(num_layers, batch_size, hidden_size, device=device) #num layers, n_seq, hidden_szie\n",
    "    memory = torch.zeros(num_layers, batch_size, hidden_size, device=device) #num_layers, n_seq, hidden_size\n",
    "    \n",
    "    data_pred, _, _ = lob_lstm(seq_block, hidden, memory) #n_seq, seq_len, output_size\n",
    "\n",
    "    log_predictions = data_pred.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee3d22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_predictions.detach().cpu().numpy()\n",
    "y_true = data_tensor[:, :, -2:].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2652eb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3026091456413269"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_pearson_correlation(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cda60d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3474,  1.4650, -0.8866,  ...,  0.0979, -0.5473, -0.1782],\n",
       "        [-0.8295,  1.1926,  0.0080,  ...,  0.0979, -0.3795, -0.0156],\n",
       "        [-0.9033,  0.7669, -0.5886,  ...,  0.0979, -0.3795, -0.0051],\n",
       "        ...,\n",
       "        [-1.3357,  1.8091, -0.4167,  ..., -0.3723,  0.3330, -0.8313],\n",
       "        [-0.2494, -0.5380, -0.7168,  ...,  1.5174, -0.2117, -1.1880],\n",
       "        [-0.9689,  0.3098, -0.9923,  ..., -1.1429, -0.2117, -1.3952]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db76a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `LSTM([...]` with `torch.export.export(..., strict=False)`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:148: UserWarning: The tensor attributes self.lstm._flat_weights[0], self.lstm._flat_weights[1], self.lstm._flat_weights[2], self.lstm._flat_weights[3] were assigned during export. Such attributes must be registered as buffers using the `register_buffer` API (https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer).\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `LSTM([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/copyreg.py:104: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "  return cls.__new__(cls, *args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 8 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 18},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.10.0',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,100,32]>,\n",
       "                %\"h0\"<FLOAT,[1,1,128]>,\n",
       "                %\"c0\"<FLOAT,[1,1,128]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,100,2]>,\n",
       "                %\"hn\"<FLOAT,[1,1,128]>,\n",
       "                %\"cn\"<FLOAT,[1,1,128]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"input_mlp.0.bias\"<FLOAT,[512]>{TorchTensor(...)},\n",
       "                %\"input_mlp.2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"lstm.weight_ih_l0\"<FLOAT,[512,128]>{TorchTensor(...)},\n",
       "                %\"lstm.weight_hh_l0\"<FLOAT,[512,128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.norm1.weight\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.norm1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.fc1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.norm2.weight\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.norm2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.fc2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"res_blocks.0.fc3.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"fc_out.weight\"<FLOAT,[2,128]>{TorchTensor(...)},\n",
       "                %\"fc_out.bias\"<FLOAT,[2]>{TorchTensor<FLOAT,[2]>(Parameter containing: tensor([ 0.0067, -0.0183], requires_grad=True), name='fc_out.bias')},\n",
       "                %\"val_0\"<FLOAT,[32,512]>{Tensor(...)},\n",
       "                %\"val_7\"<FLOAT,[512,128]>{Tensor(...)},\n",
       "                %\"val_17\"<INT64,[1]>{Tensor<INT64,[1]>(array([256]), name='val_17')},\n",
       "                %\"val_21\"<INT64,[1]>{Tensor<INT64,[1]>(array([384]), name='val_21')},\n",
       "                %\"val_25\"<INT64,[1]>{Tensor<INT64,[1]>(array([512]), name='val_25')},\n",
       "                %\"val_61\"<FLOAT,[1,1024]>{Tensor(...)},\n",
       "                %\"val_75\"<INT64,[3]>{Tensor<INT64,[3]>(array([100,   1, 128]), name='val_75')},\n",
       "                %\"val_83\"<FLOAT,[128,128]>{Tensor(...)},\n",
       "                %\"val_85\"<FLOAT,[128,128]>{Tensor(...)},\n",
       "                %\"val_93\"<FLOAT,[128,128]>{Tensor(...)},\n",
       "                %\"val_102\"<INT64,[2]>{Tensor<INT64,[2]>(array([100,  -1]), name='val_102')},\n",
       "                %\"val_107\"<INT64,[3]>{Tensor<INT64,[3]>(array([  1, 100,  -1]), name='val_107')},\n",
       "                %\"val_10\"<INT64,[1]>{Tensor<INT64,[1]>(array([128]), name='val_10')},\n",
       "                %\"val_11\"<INT64,[1]>{Tensor<INT64,[1]>(array([0]), name='val_11')},\n",
       "                %\"val_12\"<INT64,[1]>{Tensor<INT64,[1]>(array([1]), name='val_12')}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_MatMul_1\n",
       "                  %\"val_1\"<FLOAT,[1,100,512]> ⬅️ ::MatMul(%\"input\", %\"val_0\"{...})\n",
       "             1 |  # node_linear\n",
       "                  %\"linear\"<FLOAT,[1,100,512]> ⬅️ ::Add(%\"val_1\", %\"input_mlp.0.bias\"{...})\n",
       "             2 |  # node_Elu_6\n",
       "                  %\"val_6\"<FLOAT,[1,100,512]> ⬅️ ::Elu(%\"linear\") {alpha=1.0}\n",
       "             3 |  # node_MatMul_8\n",
       "                  %\"val_8\"<FLOAT,[1,100,128]> ⬅️ ::MatMul(%\"val_6\", %\"val_7\"{...})\n",
       "             4 |  # node_linear_1\n",
       "                  %\"linear_1\"<FLOAT,[1,100,128]> ⬅️ ::Add(%\"val_8\", %\"input_mlp.2.bias\"{...})\n",
       "             5 |  # node_Transpose_9\n",
       "                  %\"val_9\"<FLOAT,[100,1,128]> ⬅️ ::Transpose(%\"linear_1\") {perm=(1, 0, 2)}\n",
       "             6 |  # node_Slice_13\n",
       "                  %\"val_13\"<FLOAT,[1,1,128]> ⬅️ ::Slice(%\"h0\", %\"val_11\"{[0]}, %\"val_12\"{[1]}, %\"val_11\"{[0]})\n",
       "             7 |  # node_Slice_14\n",
       "                  %\"val_14\"<FLOAT,[1,1,128]> ⬅️ ::Slice(%\"c0\", %\"val_11\"{[0]}, %\"val_12\"{[1]}, %\"val_11\"{[0]})\n",
       "             8 |  # node_Slice_15\n",
       "                  %\"val_15\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_ih_l0\"{...}, %\"val_11\"{[0]}, %\"val_10\"{[128]}, %\"val_11\"{[0]})\n",
       "             9 |  # node_Slice_18\n",
       "                  %\"val_18\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_ih_l0\"{...}, %\"val_10\"{[128]}, %\"val_17\"{[256]}, %\"val_11\"{[0]})\n",
       "            10 |  # node_Slice_22\n",
       "                  %\"val_22\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_ih_l0\"{...}, %\"val_17\"{[256]}, %\"val_21\"{[384]}, %\"val_11\"{[0]})\n",
       "            11 |  # node_Slice_26\n",
       "                  %\"val_26\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_ih_l0\"{...}, %\"val_21\"{[384]}, %\"val_25\"{[512]}, %\"val_11\"{[0]})\n",
       "            12 |  # node_Slice_27\n",
       "                  %\"val_27\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_hh_l0\"{...}, %\"val_11\"{[0]}, %\"val_10\"{[128]}, %\"val_11\"{[0]})\n",
       "            13 |  # node_Slice_29\n",
       "                  %\"val_29\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_hh_l0\"{...}, %\"val_10\"{[128]}, %\"val_17\"{[256]}, %\"val_11\"{[0]})\n",
       "            14 |  # node_Slice_32\n",
       "                  %\"val_32\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_hh_l0\"{...}, %\"val_17\"{[256]}, %\"val_21\"{[384]}, %\"val_11\"{[0]})\n",
       "            15 |  # node_Slice_35\n",
       "                  %\"val_35\"<FLOAT,[128,128]> ⬅️ ::Slice(%\"lstm.weight_hh_l0\"{...}, %\"val_21\"{[384]}, %\"val_25\"{[512]}, %\"val_11\"{[0]})\n",
       "            16 |  # node_Concat_36\n",
       "                  %\"val_36\"<FLOAT,[512,128]> ⬅️ ::Concat(%\"val_15\", %\"val_26\", %\"val_18\", %\"val_22\") {axis=0}\n",
       "            17 |  # node_Concat_37\n",
       "                  %\"val_37\"<FLOAT,[512,128]> ⬅️ ::Concat(%\"val_27\", %\"val_35\", %\"val_29\", %\"val_32\") {axis=0}\n",
       "            18 |  # node_Unsqueeze_38\n",
       "                  %\"val_38\"<FLOAT,[1,512,128]> ⬅️ ::Unsqueeze(%\"val_36\", %\"val_11\"{[0]})\n",
       "            19 |  # node_Unsqueeze_39\n",
       "                  %\"val_39\"<FLOAT,[1,512,128]> ⬅️ ::Unsqueeze(%\"val_37\", %\"val_11\"{[0]})\n",
       "            20 |  # node_lstm__2\n",
       "                  %\"val_62\"<FLOAT,[100,1,1,128]>, %\"hn\"<FLOAT,[1,1,128]>, %\"cn\"<FLOAT,[1,1,128]> ⬅️ ::LSTM(%\"val_9\", %\"val_38\", %\"val_39\", %\"val_61\"{...}, None, %\"val_13\", %\"val_14\") {hidden_size=128, layout=0, direction='forward', input_forget=0}\n",
       "            21 |  # node_Transpose_62\n",
       "                  %\"val_63\"<FLOAT,[100,1,1,128]> ⬅️ ::Transpose(%\"val_62\") {perm=(0, 2, 1, 3)}\n",
       "            22 |  # node_Reshape_75\n",
       "                  %\"val_76\"<FLOAT,[100,1,128]> ⬅️ ::Reshape(%\"val_63\", %\"val_75\"{[100, 1, 128]}) {allowzero=0}\n",
       "            23 |  # node_lstm__0\n",
       "                  %\"getitem\"<FLOAT,[1,100,128]> ⬅️ ::Transpose(%\"val_76\") {perm=(1, 0, 2)}\n",
       "            24 |  # node_layer_norm\n",
       "                  %\"layer_norm\"<FLOAT,[1,100,128]> ⬅️ ::LayerNormalization(%\"getitem\", %\"res_blocks.0.norm1.weight\"{...}, %\"res_blocks.0.norm1.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
       "            25 |  # node_Elu_79\n",
       "                  %\"val_82\"<FLOAT,[1,100,128]> ⬅️ ::Elu(%\"layer_norm\") {alpha=1.0}\n",
       "            26 |  # node_MatMul_81\n",
       "                  %\"val_84\"<FLOAT,[1,100,128]> ⬅️ ::MatMul(%\"val_82\", %\"val_83\"{...})\n",
       "            27 |  # node_linear_2\n",
       "                  %\"linear_2\"<FLOAT,[1,100,128]> ⬅️ ::Add(%\"val_84\", %\"res_blocks.0.fc3.bias\"{...})\n",
       "            28 |  # node_MatMul_83\n",
       "                  %\"val_86\"<FLOAT,[1,100,128]> ⬅️ ::MatMul(%\"val_82\", %\"val_85\"{...})\n",
       "            29 |  # node_linear_3\n",
       "                  %\"linear_3\"<FLOAT,[1,100,128]> ⬅️ ::Add(%\"val_86\", %\"res_blocks.0.fc1.bias\"{...})\n",
       "            30 |  # node_layer_norm_1\n",
       "                  %\"layer_norm_1\"<FLOAT,[1,100,128]> ⬅️ ::LayerNormalization(%\"linear_3\", %\"res_blocks.0.norm2.weight\"{...}, %\"res_blocks.0.norm2.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
       "            31 |  # node_Elu_87\n",
       "                  %\"val_92\"<FLOAT,[1,100,128]> ⬅️ ::Elu(%\"layer_norm_1\") {alpha=1.0}\n",
       "            32 |  # node_MatMul_89\n",
       "                  %\"val_94\"<FLOAT,[1,100,128]> ⬅️ ::MatMul(%\"val_92\", %\"val_93\"{...})\n",
       "            33 |  # node_linear_4\n",
       "                  %\"linear_4\"<FLOAT,[1,100,128]> ⬅️ ::Add(%\"val_94\", %\"res_blocks.0.fc2.bias\"{...})\n",
       "            34 |  # node_add\n",
       "                  %\"add\"<FLOAT,[1,100,128]> ⬅️ ::Add(%\"linear_4\", %\"linear_2\")\n",
       "            35 |  # node_Elu_93\n",
       "                  %\"val_98\"<FLOAT,[1,100,128]> ⬅️ ::Elu(%\"add\") {alpha=1.0}\n",
       "            36 |  # node_view\n",
       "                  %\"view\"<FLOAT,[100,128]> ⬅️ ::Reshape(%\"val_98\", %\"val_102\"{[100, -1]}) {allowzero=1}\n",
       "            37 |  # node_linear_5\n",
       "                  %\"linear_5\"<FLOAT,[100,2]> ⬅️ ::Gemm(%\"view\", %\"fc_out.weight\"{...}, %\"fc_out.bias\"{[0.006725909188389778, -0.018297677859663963]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            38 |  # node_view_1\n",
       "                  %\"output\"<FLOAT,[1,100,2]> ⬅️ ::Reshape(%\"linear_5\", %\"val_107\"{[1, 100, -1]}) {allowzero=1}\n",
       "            return %\"output\"<FLOAT,[1,100,2]>, %\"hn\"<FLOAT,[1,1,128]>, %\"cn\"<FLOAT,[1,1,128]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_input_mlp_0_weight: \"f32[512, 32]\", p_input_mlp_0_bias: \"f32[512]\", p_input_mlp_2_weight: \"f32[128, 512]\", p_input_mlp_2_bias: \"f32[128]\", p_lstm_weight_ih_l0: \"f32[512, 128]\", p_lstm_weight_hh_l0: \"f32[512, 128]\", p_lstm_bias_ih_l0: \"f32[512]\", p_lstm_bias_hh_l0: \"f32[512]\", p_res_blocks_0_norm1_weight: \"f32[128]\", p_res_blocks_0_norm1_bias: \"f32[128]\", p_res_blocks_0_fc1_weight: \"f32[128, 128]\", p_res_blocks_0_fc1_bias: \"f32[128]\", p_res_blocks_0_norm2_weight: \"f32[128]\", p_res_blocks_0_norm2_bias: \"f32[128]\", p_res_blocks_0_fc2_weight: \"f32[128, 128]\", p_res_blocks_0_fc2_bias: \"f32[128]\", p_res_blocks_0_fc3_weight: \"f32[128, 128]\", p_res_blocks_0_fc3_bias: \"f32[128]\", p_fc_out_weight: \"f32[2, 128]\", p_fc_out_bias: \"f32[2]\", input_seq: \"f32[1, 100, 32]\", hidden_in: \"f32[1, 1, 128]\", mem_in: \"f32[1, 1, 128]\"):\n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 100, 512]\" = torch.ops.aten.linear.default(input_seq, p_input_mlp_0_weight, p_input_mlp_0_bias);  input_seq = p_input_mlp_0_weight = p_input_mlp_0_bias = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/activation.py:616 in forward, code: return F.elu(input, self.alpha, self.inplace)\n",
       "                    elu: \"f32[1, 100, 512]\" = torch.ops.aten.elu.default(linear, 1.0);  linear = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1, 100, 128]\" = torch.ops.aten.linear.default(elu, p_input_mlp_2_weight, p_input_mlp_2_bias);  elu = p_input_mlp_2_weight = p_input_mlp_2_bias = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/rnn.py:1141 in forward, code: result = _VF.lstm(\n",
       "                    lstm = torch.ops.aten.lstm.input(linear_1, [hidden_in, mem_in], [p_lstm_weight_ih_l0, p_lstm_weight_hh_l0, p_lstm_bias_ih_l0, p_lstm_bias_hh_l0], True, 1, 0.0, False, False, True);  linear_1 = hidden_in = mem_in = p_lstm_weight_ih_l0 = p_lstm_weight_hh_l0 = p_lstm_bias_ih_l0 = p_lstm_bias_hh_l0 = None\n",
       "                    getitem: \"f32[1, 100, 128]\" = lstm[0]\n",
       "                    getitem_1: \"f32[1, 1, 128]\" = lstm[1]\n",
       "                    getitem_2: \"f32[1, 1, 128]\" = lstm[2];  lstm = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm: \"f32[1, 100, 128]\" = torch.ops.aten.layer_norm.default(getitem, [128], p_res_blocks_0_norm1_weight, p_res_blocks_0_norm1_bias);  getitem = p_res_blocks_0_norm1_weight = p_res_blocks_0_norm1_bias = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/activation.py:616 in forward, code: return F.elu(input, self.alpha, self.inplace)\n",
       "                    elu_1: \"f32[1, 100, 128]\" = torch.ops.aten.elu.default(layer_norm, 1.0);  layer_norm = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_2: \"f32[1, 100, 128]\" = torch.ops.aten.linear.default(elu_1, p_res_blocks_0_fc3_weight, p_res_blocks_0_fc3_bias);  p_res_blocks_0_fc3_weight = p_res_blocks_0_fc3_bias = None\n",
       "                    linear_3: \"f32[1, 100, 128]\" = torch.ops.aten.linear.default(elu_1, p_res_blocks_0_fc1_weight, p_res_blocks_0_fc1_bias);  elu_1 = p_res_blocks_0_fc1_weight = p_res_blocks_0_fc1_bias = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm_1: \"f32[1, 100, 128]\" = torch.ops.aten.layer_norm.default(linear_3, [128], p_res_blocks_0_norm2_weight, p_res_blocks_0_norm2_bias);  linear_3 = p_res_blocks_0_norm2_weight = p_res_blocks_0_norm2_bias = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/activation.py:616 in forward, code: return F.elu(input, self.alpha, self.inplace)\n",
       "                    elu_2: \"f32[1, 100, 128]\" = torch.ops.aten.elu.default(layer_norm_1, 1.0);  layer_norm_1 = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_4: \"f32[1, 100, 128]\" = torch.ops.aten.linear.default(elu_2, p_res_blocks_0_fc2_weight, p_res_blocks_0_fc2_bias);  elu_2 = p_res_blocks_0_fc2_weight = p_res_blocks_0_fc2_bias = None\n",
       "            \n",
       "                    # File: /var/folders/78/_0x6_2c94wl12kzgs6rpknh40000gp/T/ipykernel_23655/2114657702.py:19 in forward, code: return x + skip\n",
       "                    add: \"f32[1, 100, 128]\" = torch.ops.aten.add.Tensor(linear_4, linear_2);  linear_4 = linear_2 = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/activation.py:616 in forward, code: return F.elu(input, self.alpha, self.inplace)\n",
       "                    elu_3: \"f32[1, 100, 128]\" = torch.ops.aten.elu.default(add, 1.0);  add = None\n",
       "            \n",
       "                    # File: /var/folders/78/_0x6_2c94wl12kzgs6rpknh40000gp/T/ipykernel_23655/3037184290.py:26 in forward, code: x = x.reshape(B*T, -1)\n",
       "                    view: \"f32[100, 128]\" = torch.ops.aten.view.default(elu_3, [100, -1]);  elu_3 = None\n",
       "            \n",
       "                    # File: /Users/Q619505/PycharmProjects/personal-projects/wundern-challenge-lob/my_venv/lib/python3.14/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_5: \"f32[100, 2]\" = torch.ops.aten.linear.default(view, p_fc_out_weight, p_fc_out_bias);  view = p_fc_out_weight = p_fc_out_bias = None\n",
       "            \n",
       "                    # File: /var/folders/78/_0x6_2c94wl12kzgs6rpknh40000gp/T/ipykernel_23655/3037184290.py:28 in forward, code: x = x.reshape(B,T,-1)\n",
       "                    view_1: \"f32[1, 100, 2]\" = torch.ops.aten.view.default(linear_5, [1, 100, -1]);  linear_5 = None\n",
       "                    return (view_1, getitem_1, getitem_2)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_input_mlp_0_weight: PARAMETER target='input_mlp.0.weight'\n",
       "            p_input_mlp_0_bias: PARAMETER target='input_mlp.0.bias'\n",
       "            p_input_mlp_2_weight: PARAMETER target='input_mlp.2.weight'\n",
       "            p_input_mlp_2_bias: PARAMETER target='input_mlp.2.bias'\n",
       "            p_lstm_weight_ih_l0: PARAMETER target='lstm.weight_ih_l0'\n",
       "            p_lstm_weight_hh_l0: PARAMETER target='lstm.weight_hh_l0'\n",
       "            p_lstm_bias_ih_l0: PARAMETER target='lstm.bias_ih_l0'\n",
       "            p_lstm_bias_hh_l0: PARAMETER target='lstm.bias_hh_l0'\n",
       "            p_res_blocks_0_norm1_weight: PARAMETER target='res_blocks.0.norm1.weight'\n",
       "            p_res_blocks_0_norm1_bias: PARAMETER target='res_blocks.0.norm1.bias'\n",
       "            p_res_blocks_0_fc1_weight: PARAMETER target='res_blocks.0.fc1.weight'\n",
       "            p_res_blocks_0_fc1_bias: PARAMETER target='res_blocks.0.fc1.bias'\n",
       "            p_res_blocks_0_norm2_weight: PARAMETER target='res_blocks.0.norm2.weight'\n",
       "            p_res_blocks_0_norm2_bias: PARAMETER target='res_blocks.0.norm2.bias'\n",
       "            p_res_blocks_0_fc2_weight: PARAMETER target='res_blocks.0.fc2.weight'\n",
       "            p_res_blocks_0_fc2_bias: PARAMETER target='res_blocks.0.fc2.bias'\n",
       "            p_res_blocks_0_fc3_weight: PARAMETER target='res_blocks.0.fc3.weight'\n",
       "            p_res_blocks_0_fc3_bias: PARAMETER target='res_blocks.0.fc3.bias'\n",
       "            p_fc_out_weight: PARAMETER target='fc_out.weight'\n",
       "            p_fc_out_bias: PARAMETER target='fc_out.bias'\n",
       "            input_seq: USER_INPUT\n",
       "            hidden_in: USER_INPUT\n",
       "            mem_in: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            view_1: USER_OUTPUT\n",
       "            getitem_1: USER_OUTPUT\n",
       "            getitem_2: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.randn(1, 100, 32) #data_tensor[1:2,:100,:-2] #time stemp only 1 to force dynamic time\n",
    "batch_size = test_input.shape[0]\n",
    "lob_lstm.eval()\n",
    "h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "m0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "torch.onnx.export(\n",
    "    lob_lstm,\n",
    "    (test_input, h0, m0),\n",
    "    f\"{pd.Timestamp.today().date()}_lstm_v1.onnx\",\n",
    "    opset_version=18,\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "     input_names=[\"input\", \"h0\", \"c0\"],\n",
    "    output_names=[\"output\", \"hn\", \"cn\"],\n",
    " #   dynamic_axes={\n",
    "  #     \"input\":  {0: \"batch\", 1: \"time\"},\n",
    "   #     \"output\": {0: \"batch\", 1: \"time\"},\n",
    "   #     \"h0\":     {1: \"batch\"},\n",
    "   #     \"c0\":     {1: \"batch\"},\n",
    "   #     \"hn\":     {1: \"batch\"},\n",
    "   #     \"cn\":     {1: \"batch\"},\n",
    "   # }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
